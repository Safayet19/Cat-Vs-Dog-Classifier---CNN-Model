# -*- coding: utf-8 -*-
"""Dog Vs Cat Classifier CNN Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B7-a_v8V6vYJOc3Mo15AzOOk2JoQi7b-

1. **Clean dataset** â†’ remove corrupted images.
2. **Normalize images** â†’ pixel values 0â€“1.
3. **Create train/validation datasets** â†’ shuffle and batch.
4. **Build CNN model** â†’ Conv2D, MaxPooling, Flatten, Dense, Dropout.
5. **Compile model** â†’ optimizer, loss, metrics.
6. **Train model** â†’ use `model.fit(train_ds, validation_data=val_ds, epochs=...)`.
7. **Check results** â†’ plot accuracy/loss or evaluate on validation set.
8. **Save model** â†’ `model.save(...)`.
9. **Deploy / predict** â†’ load model and run predictions.

**Download and Unzip the Dataset**
"""

!pip install kagglehub

import kagglehub

# Download dataset
path = kagglehub.dataset_download("bhavikjikadara/dog-and-cat-classification-dataset")
print("Path to dataset files:", path)

"""**Create Dataframes From Data. 1 = Cat , 0 = Dog**"""

# -------------------------------
# Step 1: Import required libraries
# -------------------------------
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import warnings
from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator

warnings.filterwarnings('ignore')

# -------------------------------
# Step 2: Prepare the DataFrame
# -------------------------------

# Base path to dataset
base_path = "/kaggle/input/dog-and-cat-classification-dataset/PetImages"

# Initialize lists
input_path = []  # store the path of images
label = []       # label: 0 for Cat, 1 for Dog

# Loop through each class folder
for class_name in os.listdir(base_path):  # class_name will be 'Cat' or 'Dog'
    class_path = os.path.join(base_path, class_name)
    for f in os.listdir(class_path):
        input_path.append(f)
        label.append(0 if class_name == "Cat" else 1)

# Create DataFrame
df = pd.DataFrame({
    "file": input_path,               # image file names
    "label": label                    # numeric labels
})

# Map numeric labels to class names
df['label_name'] = df['label'].map({0: 'Cat', 1: 'Dog'})

# Prepend subfolder to file column so generator can find images
df['file'] = df['label_name'] + '/' + df['file'] #It adds the subfolder name (Cat or Dog) in front of each filename so the generator can locate the images.

# -------------------------------
# Step 3: Check DataFrame info
# -------------------------------
print(df.head())
print(df['label_name'].value_counts())  # check number of cats and dogs

"""**Explotary Data Analysis**"""

# -------------------------------
# Step 4: Display some sample images
# -------------------------------
sample = df.sample(5)

plt.figure(figsize=(15, 5))
for i, row in enumerate(sample.itertuples(), 1):
    img_path = os.path.join(base_path, str(row.label_name), str(row.file).split('/')[-1])  # full path
    img = load_img(img_path, target_size=(150, 150))
    plt.subplot(1, 5, i)
    plt.imshow(img)
    plt.title(row.label_name)
    plt.axis('off')
plt.show()

"""**Create DataGenerator for the images**

A **DataGenerator** is a Python object that **loads and preprocesses images in batches** during model training instead of loading all at once.
It helps **save memory** and can **apply real-time data augmentation** like rotation, flipping, or scaling.
Basically, it **feeds the model images batch by batch efficiently**.

"""

# -------------------------------
# Step 5: Create ImageDataGenerator
# -------------------------------
train_datagen = ImageDataGenerator(
    rescale=1./255,            # normalize pixel values 0 to 1
    shear_range=0.2,           # randomly apply shearing
    zoom_range=0.2,            # randomly zoom in/out
    horizontal_flip=True,      # randomly flip images horizontally
    rotation_range=40,         # augment(rotation) images to avoid overfitting
    fill_mode='nearest'        # fill in new pixels
)

# -------------------------------
# Step 6: Create training generator
# -------------------------------
train_generator = train_datagen.flow_from_dataframe(
    df,                           # input DataFrame with file names and labels
    x_col="file",                 # column in df containing image file names (with subfolder)
    y_col="label_name",           # column in df containing labels
    target_size=(128, 128),       # resize all images to 150x150
    batch_size=16,                # number of images per batch
    class_mode="binary",          # for binary labels
    shuffle=True,                 # shuffle data each epoch
    directory=base_path           # base directory containing Cat and Dog folders
)

"""**Model Creation**



"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# -------------------------------
# Step 1: Create CNN model
# -------------------------------
model = Sequential([

    # Input shape is 150x150 RGB images
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),# First convolutional layer: 32 filters, 3x3 kernel, ReLU activation
    MaxPooling2D(2,2), # First max pooling layer: reduce spatial dimensions by 2
    Conv2D(64, (3,3), activation='relu'), # Second convolutional layer: 64 filters, 3x3 kernel, ReLU activation
    MaxPooling2D(2,2),   # Second max pooling layer
    Conv2D(128, (3,3), activation='relu'),  # Third convolutional layer: 128 filters, 3x3 kernel, ReLU activation
    MaxPooling2D(2,2),# Third max pooling layer
    Flatten(), # Flatten layer: convert 3D feature maps to 1D vector for dense layers
    Dense(512, activation='relu'),# Fully connected dense layer with 512 neurons and ReLU activation
    Dropout(0.5),# Dropout layer to prevent overfitting (randomly disable 50% of neurons during training)
    Dense(1, activation='sigmoid') # Output layer: 1 neuron with sigmoid activation for binary classification (Cat vs Dog)
])

# -------------------------------
# Step 2: Compile the model
# -------------------------------
model.compile(
    loss='binary_crossentropy',          # use binary cross-entropy for 2-class classification
    optimizer='adam',                    # Adam optimizer for weight updates
    metrics=['accuracy']                 # evaluate the model using accuracy
)

# -------------------------------
# Step 3: Display model summary
# -------------------------------
model.summary()  # prints layer info, output shapes, and total parameters

"""The CNN model has 3 convolutional layers with increasing filters (32 â†’ 64 â†’ 128), each followed by max pooling to reduce image size. The feature maps are flattened and passed through a dense layer of 512 neurons with dropout for regularization. The output layer has 1 neuron with sigmoid activation for binary classification (Cat vs Dog). The model has **19 million trainable parameters** and no non-trainable parameters. Itâ€™s ready to learn features from your images.

"""



"""**Train the model**"""

# -------------------------------
# Step : Train the CNN model
# -------------------------------
history = model.fit(
    train_generator,           # training data generator
    steps_per_epoch=len(train_generator),  # number of batches per epoch
    epochs=5,                 # number of times to iterate over dataset
    verbose=1                  # display training progress
)

"""**Evaluate the model**"""

# -------------------------------
# Plot training accuracy and loss
# -------------------------------
plt.figure(figsize=(12,5))

# Plot accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Training Loss', color='red')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Print final training accuracy and loss
final_acc = history.history['accuracy'][-1]
final_loss = history.history['loss'][-1]
print(f"Final Training Accuracy: {final_acc*100:.2f}%")
print(f"Final Training Loss: {final_loss:.4f}")

"""**Save the model**"""

# Save as HDF5
model.save("cat_dog_model.h5")

# # OR save as TensorFlow SavedModel
# model.save("cat_dog_model_tf", save_format='tf')

"""**Load saved model later**"""

from tensorflow.keras.models import load_model

# Load HDF5 model
model = load_model("cat_dog_model.h5")

"""**Prediction**"""

from google.colab import files
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

# -------------------------------
# Step 9: Upload image
# -------------------------------
uploaded = files.upload()  # user selects image(s)

# -------------------------------
# Step 10: Predict and display results
# -------------------------------
for filename in uploaded.keys():
    # Load and preprocess image
    img = load_img(filename, target_size=(128,128))
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    # Make prediction
    prediction = model.predict(img_array)[0][0]

    # Interpret and decorate output
    if prediction > 0.5:
        label = "Dog ğŸ¶"
        confidence = prediction * 100
    else:
        label = "Cat ğŸ±"
        confidence = (1 - prediction) * 100

    print("==========================================")
    print(f"File: {filename}")
    print(f"Prediction: {label}")
    print(f"Confidence: {confidence:.2f}%")
    print("==========================================\n")

"""**For Live View**"""

!pip install streamlit --quiet
!pip install pillow --quiet
!pip install tensorflow --quiet

# -------------------------------
# streamlit_app.py
# -------------------------------

import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np
from PIL import Image

# -------------------------------
# Load model
# -------------------------------
model = load_model("cat_dog_model.h5")

# -------------------------------
# Page configuration
# -------------------------------
st.set_page_config(
    page_title="ğŸ¶ğŸ± Cat vs Dog Classifier",
    page_icon="ğŸ¾",
    layout="wide"
)

# -------------------------------
# Custom CSS for styling
# -------------------------------
st.markdown("""
    <style>
    .stApp {
        background: linear-gradient(to right, #FFF7E6, #FFE6F0);
        font-family: 'Arial', sans-serif;
    }
    .title {
        color: #FF5733;
        font-size: 50px;
        font-weight: bold;
        text-align: center;
    }
    .footer {
        color: gray;
        font-size: 14px;
        text-align: center;
        margin-top: 20px;
    }
    .prediction {
        font-size: 25px;
        font-weight: bold;
        text-align: center;
    }
    </style>
""", unsafe_allow_html=True)

# -------------------------------
# Title and subtitle
# -------------------------------
st.markdown("<h1 class='title'>ğŸ¾ Cat vs Dog Classifier ğŸ¾</h1>", unsafe_allow_html=True)
st.markdown("<h3 style='text-align:center;'>Upload one or more images to see predictions instantly!</h3>", unsafe_allow_html=True)
st.markdown("---")

# -------------------------------
# File uploader (multiple images)
# -------------------------------
uploaded_files = st.file_uploader(
    "Choose cat or dog images (jpg/png):", type=["jpg","png"], accept_multiple_files=True
)

if uploaded_files:
    st.write(f"Uploaded {len(uploaded_files)} image(s) âœ…")

    cols = st.columns(len(uploaded_files))
    for i, uploaded_file in enumerate(uploaded_files):
        img = Image.open(uploaded_file)
        img_resized = img.resize((128,128))
        img_array = img_to_array(img_resized)/255.0
        img_array = np.expand_dims(img_array, axis=0)

        # Prediction
        pred = model.predict(img_array)[0][0]
        if pred > 0.5:
            label = "Dog ğŸ¶"
            confidence = pred * 100
            color = "#FF6F61"
        else:
            label = "Cat ğŸ±"
            confidence = (1-pred) * 100
            color = "#6FA8DC"

        with cols[i]:
            st.image(img, caption=uploaded_file.name, use_column_width=True)
            st.markdown(f"<p class='prediction' style='color:{color};'>{label}</p>", unsafe_allow_html=True)
            st.progress(int(confidence))

# -------------------------------
# Footer / copyright
# -------------------------------
st.markdown("<hr>", unsafe_allow_html=True)
st.markdown("<p class='footer'>Â© 2025 Safayet Ullah, Southeast University | Made with â¤ï¸ & Python ğŸ | Powered by Streamlit</p>", unsafe_allow_html=True)

